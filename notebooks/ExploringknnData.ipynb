{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All in One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2681903/2681903 [21:09<00:00, 2112.03it/s] \n",
      "  0%|          | 20/1112344 [00:00<10:29:15, 29.46it/s]/home/sebastian/Dokumente/Python-Git/py-ma-git/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1112344/1112344 [12:13<00:00, 1516.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainlimit: 2681903\n",
      "Testlimit: 1112344\n",
      "(2681903, 38)\n",
      "(2681903, 38)\n",
      "(1112344, 38)\n",
      "(1112344, 38)\n",
      "Done with 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2681903/2681903 [27:03<00:00, 1652.08it/s] \n",
      "100%|██████████| 1112344/1112344 [11:55<00:00, 1553.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2681903, 35)\n",
      "(2681903, 35)\n",
      "(1112344, 35)\n",
      "(1112344, 35)\n",
      "Done with 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2839662/2839662 [28:56<00:00, 1635.19it/s] \n",
      "100%|██████████| 1177776/1177776 [12:36<00:00, 1556.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2839662, 32)\n",
      "(2681903, 32)\n",
      "(1177776, 32)\n",
      "(1112344, 32)\n",
      "Done with 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2839662/2839662 [28:43<00:00, 1647.86it/s] \n",
      "100%|██████████| 1177776/1177776 [12:36<00:00, 1556.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2839662, 29)\n",
      "(2681903, 29)\n",
      "(1177776, 29)\n",
      "(1112344, 29)\n",
      "Done with 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2839662/2839662 [30:52<00:00, 1532.63it/s] \n",
      "100%|██████████| 1177776/1177776 [12:35<00:00, 1558.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2839662, 26)\n",
      "(2681903, 26)\n",
      "(1177776, 26)\n",
      "(1112344, 26)\n",
      "Done with 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2839662/2839662 [30:45<00:00, 1538.60it/s] \n",
      "  0%|          | 0/1177776 [00:00<?, ?it/s]/home/sebastian/Dokumente/Python-Git/py-ma-git/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1177776/1177776 [12:37<00:00, 1553.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2839662, 23)\n",
      "(2681903, 23)\n",
      "(1177776, 23)\n",
      "(1112344, 23)\n",
      "Done with 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2839662/2839662 [30:50<00:00, 1534.54it/s] \n",
      "100%|██████████| 1177776/1177776 [12:33<00:00, 1562.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2839662, 20)\n",
      "(2681903, 20)\n",
      "(1177776, 20)\n",
      "(1112344, 20)\n",
      "Done with 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2997421/2997421 [30:32<00:00, 1635.28it/s] \n",
      "100%|██████████| 1243208/1243208 [13:16<00:00, 1560.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2997421, 17)\n",
      "(2681903, 17)\n",
      "(1243208, 17)\n",
      "(1112344, 17)\n",
      "Done with 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2997421/2997421 [32:38<00:00, 1530.29it/s] \n",
      "100%|██████████| 1243208/1243208 [13:16<00:00, 1560.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2997421, 14)\n",
      "(2681903, 14)\n",
      "(1243208, 14)\n",
      "(1112344, 14)\n",
      "Done with 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2997421/2997421 [32:18<00:00, 1546.51it/s] \n",
      "100%|██████████| 1243208/1243208 [13:15<00:00, 1563.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2997421, 11)\n",
      "(2681903, 11)\n",
      "(1243208, 11)\n",
      "(1112344, 11)\n",
      "Done with 3\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "filename = \"aisdk-2023-11-08_1_kkn\"\n",
    "\n",
    "data =  pd.read_csv(f\"../workdir/AIS-KNN-Files/{filename}.csv\", lineterminator='$').values.reshape((-1,100,6))\n",
    "\n",
    "multiindex = pd.MultiIndex.from_product([range(s) for s in data.shape], names=[\"track\", \"timeindex\", \"column\"])\n",
    "data = pd.Series(data.flatten(), index=multiindex).unstack(level=\"column\")\n",
    "data.columns = [\"mmsi\", \"time\", \"x\", \"y\", \"deg\", \"dist\"]\n",
    "data = data.drop(columns=[\"deg\", \"dist\"])\n",
    "data[\"time\"] = pd.to_datetime(data[\"time\"], unit=\"s\")\n",
    "train_ships = pd.Series(data.mmsi.unique()).sample(frac=0.7, random_state=42)\n",
    "train = data[data.mmsi.isin(train_ships)].drop(columns=\"mmsi\")\n",
    "test = data[~data.mmsi.isin(train_ships)].drop(columns=\"mmsi\")\n",
    "\n",
    "data = []\n",
    "train_ships = []\n",
    "\n",
    "def generate_row(df):\n",
    "    df = df.copy()\n",
    "    df[\"src\"] = \"output\"\n",
    "    df[\"time\"] = (df[\"time\"].max()-df[\"time\"]).dt.total_seconds()\n",
    "    df[\"x\"] = df[\"x\"] - df[\"x\"].iloc[0]\n",
    "    df[\"y\"] = df[\"y\"] - df[\"y\"].iloc[0]\n",
    "    df.iloc[:-1,-1] = \"input_\" + pd.Series(np.arange(df.shape[0]-1)).astype(str)\n",
    "    df=df.melt(id_vars=\"src\")\n",
    "    df[\"colname\"] = df.src + \"_\" + df.variable\n",
    "    df=df.drop(columns=[\"src\", \"variable\"]).set_index(\"colname\")\n",
    "    df=df.transpose().reset_index(drop=True)\n",
    "    df.columns.name = None\n",
    "    df=df.sort_index(axis=1).drop([\"output_time\"], axis=1)\n",
    "    df=df.loc[:, ~df.columns.to_series().str.endswith('index')]\n",
    "    return df\n",
    "\n",
    "def generate_model_frame(df, known):\n",
    "    window_size = known + 1\n",
    "    skipped_windows = 4\n",
    "\n",
    "    windows = df.reset_index(drop=False).groupby('track').rolling(window_size)\n",
    "    windows = (win for i, win in enumerate(windows) if len(win) == window_size and i % (skipped_windows + 1) == 0)\n",
    "    windows = list(windows)\n",
    "    res = Parallel(n_jobs=-1)(delayed(generate_row)(win) for win in tqdm(windows))\n",
    "    return pd.concat(res, ignore_index=True)\n",
    "\n",
    "for known in range(12, 2, -1):\n",
    "    path = Path(f\"../workdir/AIS-ModelFrames/{filename}_train_{known}_0.csv\")\n",
    "    if not path.exists():     \n",
    "        train_model = generate_model_frame(train, known)\n",
    "        test_model = generate_model_frame(test, known)\n",
    "\n",
    "        if known == 12:   \n",
    "            var = list(train_model.shape)\n",
    "            var = var[0]\n",
    "            trainlimit = var\n",
    "            print(f\"Trainlimit: {trainlimit}\")\n",
    "\n",
    "            var = list(test_model.shape)\n",
    "            var = var[0]\n",
    "            testlimit = var\n",
    "            print(f\"Testlimit: {testlimit}\")\n",
    "\n",
    "        print(train_model.shape)\n",
    "        train_model = train_model.sample(n = trainlimit)\n",
    "        print(train_model.shape)\n",
    "\n",
    "        print(test_model.shape)\n",
    "        test_model = test_model.sample(n = testlimit)\n",
    "        print(test_model.shape)\n",
    "        \n",
    "        train_model.to_csv(path, index=False)\n",
    "        test_model.to_csv(f\"../workdir/AIS-ModelFrames/{filename}_test_{known}_0.csv\", index=False)\n",
    "        print(f\"Done with {known}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
