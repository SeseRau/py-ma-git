{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All in One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2838847/2838847 [31:04<00:00, 1522.76it/s] \n",
      "100%|██████████| 1264800/1264800 [13:49<00:00, 1524.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainlimit: 2838847\n",
      "Testlimit: 1264800\n",
      "(2838847, 38)\n",
      "(2838847, 38)\n",
      "(1264800, 38)\n",
      "(1264800, 38)\n",
      "Done with 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2838847/2838847 [31:01<00:00, 1524.69it/s] \n",
      "100%|██████████| 1264800/1264800 [13:41<00:00, 1540.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2838847, 35)\n",
      "(2838847, 35)\n",
      "(1264800, 35)\n",
      "(1264800, 35)\n",
      "Done with 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3005838/3005838 [32:48<00:00, 1526.59it/s] \n",
      "100%|██████████| 1339200/1339200 [14:28<00:00, 1542.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3005838, 32)\n",
      "(2838847, 32)\n",
      "(1339200, 32)\n",
      "(1264800, 32)\n",
      "Done with 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3005838/3005838 [32:51<00:00, 1524.40it/s] \n",
      "100%|██████████| 1339200/1339200 [14:26<00:00, 1546.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3005838, 29)\n",
      "(2838847, 29)\n",
      "(1339200, 29)\n",
      "(1264800, 29)\n",
      "Done with 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3005838/3005838 [32:44<00:00, 1529.81it/s] \n",
      "100%|██████████| 1339200/1339200 [14:14<00:00, 1567.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3005838, 26)\n",
      "(2838847, 26)\n",
      "(1339200, 26)\n",
      "(1264800, 26)\n",
      "Done with 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3005838/3005838 [32:27<00:00, 1543.11it/s] \n",
      "100%|██████████| 1339200/1339200 [14:11<00:00, 1573.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3005838, 23)\n",
      "(2838847, 23)\n",
      "(1339200, 23)\n",
      "(1264800, 23)\n",
      "Done with 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3005838/3005838 [31:46<00:00, 1576.85it/s] \n",
      "100%|██████████| 1339200/1339200 [13:59<00:00, 1595.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3005838, 20)\n",
      "(2838847, 20)\n",
      "(1339200, 20)\n",
      "(1264800, 20)\n",
      "Done with 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3172829/3172829 [33:47<00:00, 1565.18it/s] \n",
      "  0%|          | 0/1413600 [00:00<?, ?it/s]/home/sebastian/Dokumente/Python-Git/py-ma-git/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1413600/1413600 [14:46<00:00, 1595.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3172829, 17)\n",
      "(2838847, 17)\n",
      "(1413600, 17)\n",
      "(1264800, 17)\n",
      "Done with 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3172829/3172829 [33:27<00:00, 1580.40it/s] \n",
      "100%|██████████| 1413600/1413600 [14:42<00:00, 1601.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3172829, 14)\n",
      "(2838847, 14)\n",
      "(1413600, 14)\n",
      "(1264800, 14)\n",
      "Done with 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3172829/3172829 [33:23<00:00, 1583.34it/s] \n",
      "100%|██████████| 1413600/1413600 [14:45<00:00, 1596.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3172829, 11)\n",
      "(2838847, 11)\n",
      "(1413600, 11)\n",
      "(1264800, 11)\n",
      "Done with 3\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "#filename = \"aisdk-2023-11-08_1_knn\"\n",
    "filename = \"aisdk-2023-11-09_1_knn\"\n",
    "\n",
    "data =  pd.read_csv(f\"../workdir/AIS-KNN-Files/{filename}.csv\", lineterminator='$').values.reshape((-1,100,6))\n",
    "\n",
    "multiindex = pd.MultiIndex.from_product([range(s) for s in data.shape], names=[\"track\", \"timeindex\", \"column\"])\n",
    "data = pd.Series(data.flatten(), index=multiindex).unstack(level=\"column\")\n",
    "data.columns = [\"mmsi\", \"time\", \"x\", \"y\", \"deg\", \"dist\"]\n",
    "data = data.drop(columns=[\"deg\", \"dist\"])\n",
    "data[\"time\"] = pd.to_datetime(data[\"time\"], unit=\"s\")\n",
    "train_ships = pd.Series(data.mmsi.unique()).sample(frac=0.7, random_state=42)\n",
    "train = data[data.mmsi.isin(train_ships)].drop(columns=\"mmsi\")\n",
    "test = data[~data.mmsi.isin(train_ships)].drop(columns=\"mmsi\")\n",
    "\n",
    "data = []\n",
    "train_ships = []\n",
    "\n",
    "def generate_row(df):\n",
    "    df = df.copy()\n",
    "    df[\"src\"] = \"output\"\n",
    "    df[\"time\"] = (df[\"time\"].max()-df[\"time\"]).dt.total_seconds()\n",
    "    df[\"x\"] = df[\"x\"] - df[\"x\"].iloc[0]\n",
    "    df[\"y\"] = df[\"y\"] - df[\"y\"].iloc[0]\n",
    "    df.iloc[:-1,-1] = \"input_\" + pd.Series(np.arange(df.shape[0]-1)).astype(str)\n",
    "    df=df.melt(id_vars=\"src\")\n",
    "    df[\"colname\"] = df.src + \"_\" + df.variable\n",
    "    df=df.drop(columns=[\"src\", \"variable\"]).set_index(\"colname\")\n",
    "    df=df.transpose().reset_index(drop=True)\n",
    "    df.columns.name = None\n",
    "    df=df.sort_index(axis=1).drop([\"output_time\"], axis=1)\n",
    "    df=df.loc[:, ~df.columns.to_series().str.endswith('index')]\n",
    "    return df\n",
    "\n",
    "def generate_model_frame(df, known):\n",
    "    window_size = known + 1\n",
    "    skipped_windows = 4\n",
    "\n",
    "    windows = df.reset_index(drop=False).groupby('track').rolling(window_size)\n",
    "    windows = (win for i, win in enumerate(windows) if len(win) == window_size and i % (skipped_windows + 1) == 0)\n",
    "    windows = list(windows)\n",
    "    res = Parallel(n_jobs=-1)(delayed(generate_row)(win) for win in tqdm(windows))\n",
    "    return pd.concat(res, ignore_index=True)\n",
    "\n",
    "for known in range(12, 2, -1):\n",
    "    path = Path(f\"../workdir/AIS-ModelFrames/{filename}_train_{known}_0.csv\")\n",
    "    if not path.exists():     \n",
    "        train_model = generate_model_frame(train, known)\n",
    "        test_model = generate_model_frame(test, known)\n",
    "\n",
    "        if known == 12:   \n",
    "            var = list(train_model.shape)\n",
    "            var = var[0]\n",
    "            trainlimit = var\n",
    "            print(f\"Trainlimit: {trainlimit}\")\n",
    "\n",
    "            var = list(test_model.shape)\n",
    "            var = var[0]\n",
    "            testlimit = var\n",
    "            print(f\"Testlimit: {testlimit}\")\n",
    "\n",
    "        print(train_model.shape)\n",
    "        train_model = train_model.sample(n = trainlimit)\n",
    "        print(train_model.shape)\n",
    "\n",
    "        print(test_model.shape)\n",
    "        test_model = test_model.sample(n = testlimit)\n",
    "        print(test_model.shape)\n",
    "        \n",
    "        train_model.to_csv(path, index=False)\n",
    "        test_model.to_csv(f\"../workdir/AIS-ModelFrames/{filename}_test_{known}_0.csv\", index=False)\n",
    "        print(f\"Done with {known}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
